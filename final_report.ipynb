{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Project's goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Project's constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will analyze the structure of the Computer vision implementation for our project. For this we will start by enumerating the different external libraries that we used, then we will explain how we initialize our scene in our code, to finally detail the methods used to detect the obstacle, the robot and the destination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 External Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer vision we used external libraries to help us in various tasks, we thus reference them here before introducing our implementation.\n",
    "\n",
    "We used:\n",
    "1. OpenCV-Contrib-Python which is a library that contains all opencv functions plus some funcitons added by contributors. OpenCV provided a rich set of functions that helped us process the images of our camera.\n",
    "2. Numpy library for its easy data structures and mathematical operations.\n",
    "3. Aruco library to handle the detection of our Aruco tags.\n",
    "4. Scipy to handle transformation between rotation matrixs,quaternions and Euler angles.\n",
    "\n",
    "NOTE: from now on the term \"tag\" or \"marker\" refers to ArUCo Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Vision module structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computer vision module is divided into several sub modules, shown on the diagram below:\n",
    "vision.py is the main file containing the Map class definition, its attributes and functions to be called in the main and through other modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Scene initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the scene, we chose to create a Map class, which will be in charge of handing every vision variable and functions as attributes and methods, as shown below (which only contains the class attributes, the methods will be shown further below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from constants import *\n",
    "\n",
    "class Map:\n",
    "    def __init__(self):\n",
    "        # Initialilze camera video capture\n",
    "        self.capture = cv.VideoCapture(0)\n",
    "        # Drop the first x frames\n",
    "        for _ in range(FIRST_FRAME):\n",
    "            self.capture.read()\n",
    "        \n",
    "        # Define class attributes\n",
    "        self.success = True\n",
    "        self.raw_frame = None\n",
    "        self.frame = None\n",
    "        self.robot = 3*[None]\n",
    "        self.destination = 3*[None]\n",
    "        self.map_corners = {}\n",
    "        self.found_corners = False\n",
    "        self.found_robot = False\n",
    "        self.found_destination = False\n",
    "        self.obstacles = []\n",
    "        self.obstacles_lines = []\n",
    "        self.target_lines = []\n",
    "        self.pose_est = 3*[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Map class starts by initializing a capture for our camera to take pictures from, using opencv's method VideoCapture.\n",
    "- Then it drops the first X frame to let the camera adapt its settings to the environment.\n",
    "- It then initializes the rest of the class attributes:\n",
    "1. success: False if it fails an image treatment\n",
    "2. raw_frame: Raw captured frame of the camera\n",
    "3. frame: Raw frame treated\n",
    "4. robot: Contains the robot position in (x,y) and its orientation.\n",
    "5. destination: Contains the destination's position in (x,y) and the corners of the detected aruco tag\n",
    "6. map_corners: if the aruco tags in the corners are detected, this maps them to the pixel that we will use to crop the image\n",
    "7. found_corners: is true if the aruco tags in the corners are detected\n",
    "8. found_robot: is true if the robot tag is detected\n",
    "9. found_destination: is true if the destination tag is detected\n",
    "10. obstacles: list of obstacles, each defined as a list of points\n",
    "11. possible_lines: list of lines of the computed visibility graph\n",
    "12. target_lines: list of points that creates the computed shortest path\n",
    "13. pose_est: position estimation of the kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Detection of obstacles, Thymio and goal point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Global Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Path planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Robot's actuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Local Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Obstacle avoidance (Artificial Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Completion of the obstacle avoidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Position Estimation: Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Empirical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Kalman filtering theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Video Demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Global example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Specific cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Obstacle avoidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Kidnapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Change in goal's position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Hidden Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
